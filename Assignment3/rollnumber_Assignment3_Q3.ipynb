{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WygtNaNKhey6"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "## Instructions\n",
        "- Run this notebook on ```Google Colab(preferable)```\n",
        "- Write your code and analysis in the indicated cells.\n",
        "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
        "- Do not attempt to change the contents of other cells. \n",
        "\n",
        "## Packages Used\n",
        "- sklearn [link](https://scikit-learn.org/)\n",
        "- Keras [link](https://keras.io/guides/)\n",
        "\n",
        "## Submission\n",
        "- Rename the notebook to `<roll_number>_Assignment3_Q3.ipynb`.\n",
        "\n",
        "\n",
        "## Question 3\n",
        "Fake news is a widespread problem and there are many methods for combating it.\n",
        "You have to build a fake news detection system using a ML model. Train any ML model (ANN, LSTM) over the given Dataset.\n",
        "The dataset has short statements spoken by people and has the meta-information and corresponding label for those sentences. \n",
        "Your target is label column which has 6 labels(in the increasing order of truthfullness): pants-fire, false, barely-true, half-true, mostly-true, true.\n",
        "\n",
        "The features are 'statement', 'subject', 'speaker', 'job', 'state', 'party', 'barely_true_c', 'false_c', 'half_true_c', 'mostly_true_c', 'pants_on_fire_c', 'venue' and the target is column \"label\".\n",
        "\n",
        "The statement is made by speaker whose job, party are given along with 6 columns which are an account of the  type of news(labels) the person has shared before. \n",
        "The person who has shared fake content before is likely to share it in future and this can be accounted by the ML model as a feature. Column barely_true_c contains how many barely_true news has the speaker shared (and so is with column X_c, value of X_c is number of X the person shared).\n",
        "\n",
        "\n",
        "You have to perform two tasks:\n",
        "* task1: Binary classification <br>\n",
        "Classify the given news as true/false. Take the labels pants-fire, false, barely-true as false and rest (half-true, mostly-true, true) as true.\n",
        "* task2: Six-way classification <br>\n",
        "Classify the given news into six-classes \"pants-fire, false, barely-true, half-true, mostly-true, true\".\n",
        "\n",
        "For each of the tasks:\n",
        "1) Experiment with depth of network and try to fine-tune hyperparameters reporting your observations. <br>\n",
        "2) Report the accuracy, f1-score, confusion matrix on train, val and test sets. <br>\n",
        "3) Experiment with bag-of-words, glove and bert embeddings(code given in the below notebook) and report results. <br> Comment on what is the affect of embedding on the results.\n",
        "\n",
        "The pre-processing code is provided, you need to write the training and test.\n",
        "\n",
        "Note: You are supposed to train on trainset, fine-tune on val and just eval on test set. If found that you trained on val/test sets, the penalty will be incurred."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzCQtjimhey-"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy\n",
        "# !pip install tensorflow\n",
        "# !pip install re\n",
        "# !pip install nltk\n",
        "# !pip install keras\n",
        "# !pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jznY2Rghk15s",
        "outputId": "4d98299f-5ae3-4fe1-feab-268b4476bbfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agl6JEo_gaBT",
        "outputId": "7c4305dc-7ade-4d67-db24-5fabcda71e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras  #feel free to use any other library\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.utils import np_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T215KosUhezB"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('drive/MyDrive/q3_data/train.csv')\n",
        "val = pd.read_csv('drive/MyDrive/q3_data/val.csv')\n",
        "test = pd.read_csv('drive/MyDrive/q3_data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enAZ4DvUffVr"
      },
      "outputs": [],
      "source": [
        "# Dropping the 'id' column\n",
        "train.drop('id', axis = 1, inplace = True)\n",
        "test.drop('id', axis = 1, inplace = True)\n",
        "val.drop('id', axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "7pEJ-G4yITrd",
        "outputId": "4d33e1b3-170f-43c9-d9ad-30ed303bb4ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         label                                          statement  \\\n",
              "0        False  Says the Annies List political group supports ...   \n",
              "1    half-true  When did the decline of coal start? It started...   \n",
              "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
              "3        False  Health care reform legislation is likely to ma...   \n",
              "4    half-true  The economic turnaround started at the end of ...   \n",
              "\n",
              "                              subject         speaker                   job  \\\n",
              "0                            abortion    dwayne-bohac  State representative   \n",
              "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
              "2                      foreign-policy    barack-obama             President   \n",
              "3                         health-care    blog-posting                   NaN   \n",
              "4                        economy,jobs   charlie-crist                   NaN   \n",
              "\n",
              "      state       party  barely_true_c  false_c  half_true_c  mostly_true_c  \\\n",
              "0     Texas  republican              0        1            0              0   \n",
              "1  Virginia    democrat              0        0            1              1   \n",
              "2  Illinois    democrat             70       71          160            163   \n",
              "3       NaN        none              7       19            3              5   \n",
              "4   Florida    democrat             15        9           20             19   \n",
              "\n",
              "   pants_on_fire_c                venue  \n",
              "0                0             a mailer  \n",
              "1                0      a floor speech.  \n",
              "2                9               Denver  \n",
              "3               44       a news release  \n",
              "4                2  an interview on CNN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd42b486-620f-4338-bc08-b13bad847a78\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>job</th>\n",
              "      <th>state</th>\n",
              "      <th>party</th>\n",
              "      <th>barely_true_c</th>\n",
              "      <th>false_c</th>\n",
              "      <th>half_true_c</th>\n",
              "      <th>mostly_true_c</th>\n",
              "      <th>pants_on_fire_c</th>\n",
              "      <th>venue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a mailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>a floor speech.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mostly-true</td>\n",
              "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
              "      <td>foreign-policy</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>President</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>160</td>\n",
              "      <td>163</td>\n",
              "      <td>9</td>\n",
              "      <td>Denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>Health care reform legislation is likely to ma...</td>\n",
              "      <td>health-care</td>\n",
              "      <td>blog-posting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>a news release</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>half-true</td>\n",
              "      <td>The economic turnaround started at the end of ...</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>charlie-crist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Florida</td>\n",
              "      <td>democrat</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>an interview on CNN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd42b486-620f-4338-bc08-b13bad847a78')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd42b486-620f-4338-bc08-b13bad847a78 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd42b486-620f-4338-bc08-b13bad847a78');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbFqDO8_U6df",
        "outputId": "0e0ccaa1-d943-4efd-c834-9cf10f69ee40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10269, 13)\n",
            "(1284, 13)\n",
            "(1283, 13)\n"
          ]
        }
      ],
      "source": [
        "# Checking the shape of data\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jcgp_xUshezD"
      },
      "source": [
        "## Clean and pre-process data\n",
        "* Replace missing values\n",
        "* Remove numbers and special characters\n",
        "* Convert to upper-case\n",
        "\n",
        "We experiment with two types of processing, one directly appending the other attributes like subject, job, state, party to sentence and then applying bag of words on it.\n",
        "\n",
        "Other being encoding sentence with glove embeddings and passing just that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7tTpAClApgJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def dataPreprocessing(data):\n",
        "    '''Function for cleaning the dataset\n",
        "    '''\n",
        "    corpus = []\n",
        "    # Missing values\n",
        "    data[\"job\"].fillna(\"no-job\", inplace = True)\n",
        "    data[\"state\"].fillna(\"no-state\", inplace = True)\n",
        "\n",
        "    for x in range(data.shape[0]):\n",
        "        statement = re.sub('[^a-zA-Z]', ' ', data['statement'][x]) # Removing all numbers and special characters\n",
        "        statement = statement.lower() # Converting uppercase to lowercase\n",
        "        statement = statement.split()\n",
        "        \n",
        "        # you can experiment with any other stemmers\n",
        "        ps = PorterStemmer()\n",
        "        statement = [ps.stem(word) for word in statement if not word in set(stopwords.words('english'))] # Stemming the dataset and removing stopwords\n",
        "        statement = ' '.join(statement)\n",
        "        subject = data['subject'][x].replace(',', ' ')\n",
        "        speaker = data['speaker'][x]\n",
        "        job = data['job'][x].lower()\n",
        "        # job = job.replace(' ', '-')\n",
        "        state = data['state'][x].lower()\n",
        "        party = data['party'][x].lower()\n",
        "        corpus.append(statement + ' '  + subject + ' ' + job + ' ' + state + ' ' + party)\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy1ikPhJ9LoS"
      },
      "outputs": [],
      "source": [
        "x_train = dataPreprocessing(train)\n",
        "x_val = dataPreprocessing(val) \n",
        "x_test = dataPreprocessing(test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s12mlSq6hezE",
        "outputId": "fc8de82c-a4e5-466b-99ff-6cbb7c3353f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10269, 1284, 1283)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "len(x_train), len(x_val), len(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb8SYKHGhezF"
      },
      "outputs": [],
      "source": [
        "corpus = x_train + x_val + x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozT5Ud_fhezF"
      },
      "source": [
        "## Using bag-of-words embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sopw2zusZwn4"
      },
      "outputs": [],
      "source": [
        "# Converting the corpus into bag-of-words\n",
        "cv = CountVectorizer(max_features = 8000)\n",
        "X = cv.fit_transform(corpus).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGVpgrEQhezG",
        "outputId": "2348366c-d74b-4886-89e9-51e1b46f385d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o06bP9FJEaMU",
        "outputId": "2d31e300-077e-4558-b58a-537302e6b03d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12836, 8000)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mUgnz93hezG",
        "outputId": "3ee3157c-34d1-4eff-c751-26b0104b1e55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['label', 'statement', 'subject', 'speaker', 'job', 'state', 'party',\n",
              "       'barely_true_c', 'false_c', 'half_true_c', 'mostly_true_c',\n",
              "       'pants_on_fire_c', 'venue'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCqMgDpiLDhu"
      },
      "outputs": [],
      "source": [
        "# Selecting the columns 'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c'\n",
        "label_cols = ['barely_true_c', 'false_c', 'half_true_c', 'mostly_true_c',\n",
        "       'pants_on_fire_c']\n",
        "x_train2 = train[label_cols]\n",
        "x_val2 = val[label_cols]\n",
        "x_test2 = test[label_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "cD5M_Y8_H-Aj",
        "outputId": "1a5d645f-c4b7-4b81-fe25-9f77eec2f95e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       barely_true_c  false_c  half_true_c  mostly_true_c  pants_on_fire_c\n",
              "0                  0        1            0              0                0\n",
              "1                  0        0            1              1                0\n",
              "2                 70       71          160            163                9\n",
              "3                  7       19            3              5               44\n",
              "4                 15        9           20             19                2\n",
              "...              ...      ...          ...            ...              ...\n",
              "10264              0        1            1              1                0\n",
              "10265              0        0            0              1                0\n",
              "10266              4       11            5              3                3\n",
              "10267              3        1            3              0                0\n",
              "10268              0        1            1              0                2\n",
              "\n",
              "[10269 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e873f53b-e16f-4fc3-9dd5-1860bfc5064b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>barely_true_c</th>\n",
              "      <th>false_c</th>\n",
              "      <th>half_true_c</th>\n",
              "      <th>mostly_true_c</th>\n",
              "      <th>pants_on_fire_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>160</td>\n",
              "      <td>163</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10264</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10265</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10266</th>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10267</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10268</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10269 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e873f53b-e16f-4fc3-9dd5-1860bfc5064b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e873f53b-e16f-4fc3-9dd5-1860bfc5064b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e873f53b-e16f-4fc3-9dd5-1860bfc5064b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "x_train2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QglKXzA_w6DH"
      },
      "outputs": [],
      "source": [
        "# Stacking x_train and x_train2 horizontally\n",
        "x_train_bow = np.hstack((X[:len(x_train)], x_train2))\n",
        "x_val_bow = np.hstack((X[len(x_train):len(x_train)+len(x_val)], x_val2))\n",
        "x_test_bow = np.hstack((X[len(x_train)+len(x_val):], x_test2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3pskgViw99U",
        "outputId": "c6d22fef-9dda-4de9-fabf-6390d383f484"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10269, 8005)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "x_train_bow.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6MiJVyChezH"
      },
      "source": [
        "## Use of Glove Embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loxPaX9ahezH"
      },
      "source": [
        "download glove embeddings from 'https://nlp.stanford.edu/data/glove.6B.zip','glove.6B.zip'\n",
        "and place in your current working folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR9HcutehezH",
        "outputId": "7a33ef27-dafb-40c3-b498-d0cf13634fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open glove.6B.zip, glove.6B.zip.zip or glove.6B.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# !wget \"https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\"\n",
        "!unzip \"glove.6B.zip\" -d \"glove\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "le_rhVpphezI"
      },
      "outputs": [],
      "source": [
        "emmbed_dict = {}\n",
        "with open('drive/MyDrive/glove/glove.6B.200d.txt','r') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:],'float32')\n",
        "    emmbed_dict[word]=vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nP2Ojx6HhezI"
      },
      "outputs": [],
      "source": [
        "emmbed_dict['oov'] = np.zeros(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K86-xdAJhezI",
        "outputId": "b666a2a0-579d-4dda-951b-0582cf23c7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.96)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.18.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTqWCeSBhezI",
        "outputId": "c98e2250-088d-4490-fa05-6e9da6075100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "def dataPreprocessing_glove(data):\n",
        "    corpus = []\n",
        "    # Missing values\n",
        "    data[\"job\"].fillna(\"no-job\", inplace = True)\n",
        "    data[\"state\"].fillna(\"no-state\", inplace = True)\n",
        "\n",
        "    for x in range(data.shape[0]):\n",
        "        statement = re.sub('[^a-zA-Z]', ' ', data['statement'][x]) # Removing all numbers and special characters\n",
        "        statement = statement.lower() # Converting uppercase to lowercase\n",
        "        statement = word_tokenize(statement)\n",
        "        \n",
        "        if(len(statement)<40):\n",
        "          tmp = len(statement)\n",
        "          while tmp < 40:\n",
        "            statement.append('ashishrai')\n",
        "            tmp += 1\n",
        "        else:\n",
        "          statement = statement[:40]\n",
        "\n",
        "        embed_statement = []\n",
        "        for w in statement:\n",
        "            if w in emmbed_dict:\n",
        "                embed_statement.append(emmbed_dict[w])\n",
        "            else:\n",
        "                embed_statement.append(emmbed_dict['oov'])\n",
        "         \n",
        "        # bonus: Think how you can encode the below features(hint: look upon label encoding or training your own word2vec or any other embedding model)\n",
        "    \n",
        "#         subject = data['subject'][x].replace(',', ' ')\n",
        "#         speaker = data['speaker'][x]\n",
        "#         job = data['job'][x].lower()\n",
        "#         # job = job.replace(' ', '-')\n",
        "#         state = data['state'][x].lower()\n",
        "#         party = data['party'][x].lower()\n",
        "        corpus.append(embed_statement)\n",
        "    \n",
        "    return np.array(corpus)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql70qe9shezI"
      },
      "outputs": [],
      "source": [
        "x_train_glove = dataPreprocessing_glove(train)\n",
        "x_val_glove = dataPreprocessing_glove(val) \n",
        "x_test_glove = dataPreprocessing_glove(test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDzCyvyjSpYD"
      },
      "outputs": [],
      "source": [
        "# x_train_glove = np.asarray(x_train_glove)\n",
        "# print(x_train_glove.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaKYAoN6hezI"
      },
      "outputs": [],
      "source": [
        "x_train_glove = np.hstack((x_train_glove.reshape(-1,8000), x_train2))\n",
        "x_val_glove = np.hstack((x_val_glove.reshape(-1,8000), x_val2))\n",
        "x_test_glove = np.hstack((x_test_glove.reshape(-1,8000), x_test2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGcR4xn-hezI"
      },
      "source": [
        "## Use of bert embeddings\n",
        "note: we used our pre-processed code for bow which has the attributed appended to end the end of sentence. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayYNhuMphezJ"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "x_train_bert = np.hstack((model.encode(x_train), x_train2))\n",
        "x_val_bert = np.hstack((model.encode(x_val), x_val2))\n",
        "x_test_bert = np.hstack((model.encode(x_test), x_test2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzQLWL9ChezJ"
      },
      "source": [
        "Now use the above 3 types of embedded inputs(bow, glove, bert embeddings) for the 2 classification tasks and compare their outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmavEzWHrTC8"
      },
      "source": [
        "# Six-way classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wAhr39Aq41J"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJwZwMXANg9_"
      },
      "outputs": [],
      "source": [
        "num_classes = 6\n",
        "# Preprocessing function for the labels\n",
        "def categorize(data):\n",
        "    y = data[\"label\"].tolist()\n",
        "\n",
        "    # Encoding the Dependent Variable\n",
        "    labelencoder_y = LabelEncoder()\n",
        "    y = labelencoder_y.fit_transform(y)\n",
        "\n",
        "    # Converting to binary class matrix\n",
        "    y = np_utils.to_categorical(y, num_classes)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIKTUSM3MJ-u"
      },
      "outputs": [],
      "source": [
        "y_train_six_way = categorize(train)\n",
        "y_test_six_way = categorize(test)\n",
        "y_val_six_way = categorize(val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7pAGF06hezJ"
      },
      "source": [
        "Build a model and pass bow, glove and bert embedded inputs: x_train_bow, x_train_glove, x_train_bert(similarly validate for val and report results on test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y-dusAUolnI"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuf7DGvhxGvk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "\n",
        "# class LSTM_Model:\n",
        "#   def __init__(self, input, output, units ):\n",
        "#     self.model = Sequential()\n",
        "#     self.model.add(Input(input))\n",
        "#     self.model.add(LSTM(units=units))\n",
        "#     self.model.add(Dense(units=output, activation='softmax'))\n",
        "#     self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#   def print_summary(self):\n",
        "#     print(self.model.summary())\n",
        "\n",
        "#   def train(self, x_train, y_train, validation_data, batch_size=64, epochs=3):\n",
        "#     self.model.fit(x_train, y_train, validation_data=validation_data, batch_size=batch_size, epochs=epochs)\n",
        "#     return self.model\n",
        "\n",
        "#   def model_evaluate(model, x_test, y_test):\n",
        "#     y_test = np.argmax(y_test, axis=1)\n",
        "#     y_pred = model.predict(x_test)\n",
        "#     y_pred = np.argmax(y_pred)\n",
        "#     acc = accuracy_score(y_test, y_pred)\n",
        "#     f1 = f1_score(y_test, y_pred, average='micro')\n",
        "#     con_mat = confusion_matrix(y_test, y_pred)\n",
        "#     print(\"accuracy: \", acc)\n",
        "#     print(\"f1 score\", f1_score)\n",
        "#     print(\"Confusion Matrix\", con_mat)\n",
        "\n",
        "\n",
        "def print_metrics(y_test, y_pred):\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
        "  con_mat = confusion_matrix(y_test, y_pred)\n",
        "  print(\"accuracy: \", acc)\n",
        "  print(\"f1 score\", f1)\n",
        "  print(\"Confusion Matrix: \\n\", con_mat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TSSvuMK3zgJ"
      },
      "source": [
        "### Six way classification: **Bag of words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQdxAfa6hezJ",
        "outputId": "1e211bcc-1791-4e30-dfd0-8bc238bd54f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_7 (LSTM)               (None, 100)               40800     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 6)                 606       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,406\n",
            "Trainable params: 41,406\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "161/161 [==============================] - 64s 373ms/step - loss: 1.7319 - accuracy: 0.2306 - val_loss: 1.7091 - val_accuracy: 0.2305\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 56s 350ms/step - loss: 1.7516 - accuracy: 0.2679 - val_loss: 1.8802 - val_accuracy: 0.1846\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 52s 320ms/step - loss: 1.7448 - accuracy: 0.2235 - val_loss: 1.7191 - val_accuracy: 0.2453\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 52s 322ms/step - loss: 1.7028 - accuracy: 0.2389 - val_loss: 1.6960 - val_accuracy: 0.2656\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 54s 337ms/step - loss: 1.7019 - accuracy: 0.2400 - val_loss: 1.7091 - val_accuracy: 0.2407\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 51s 318ms/step - loss: 1.6993 - accuracy: 0.2392 - val_loss: 1.6950 - val_accuracy: 0.2671\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 52s 322ms/step - loss: 1.6958 - accuracy: 0.2522 - val_loss: 1.7009 - val_accuracy: 0.2765\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 51s 319ms/step - loss: 1.6954 - accuracy: 0.2472 - val_loss: 1.6938 - val_accuracy: 0.2578\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 51s 318ms/step - loss: 1.6982 - accuracy: 0.2421 - val_loss: 1.6964 - val_accuracy: 0.2687\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 54s 334ms/step - loss: 1.6958 - accuracy: 0.2524 - val_loss: 1.6964 - val_accuracy: 0.2523\n",
            "accuracy:  0.24551831644583008\n",
            "f1 score 0.24551831644583008\n",
            "Confusion Matrix: \n",
            " [[ 56   1   0 172   6  15]\n",
            " [ 29   1   0 164  14   3]\n",
            " [ 52   0   0 147   9   6]\n",
            " [ 37   1   0 208  17   4]\n",
            " [ 27   3   0 190  25   4]\n",
            " [ 55   0   0  11   1  25]]\n"
          ]
        }
      ],
      "source": [
        "!pip install keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "## write your code here\n",
        "# Initialize hyperparameters\n",
        "# Create model\n",
        "# train\n",
        "# test\n",
        "# report accuracy, f1-score and confusion matrix\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input((8005,1)))\n",
        "model.add(LSTM(units=100))\n",
        "model.add(Dense(units=6, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_bow = model.fit(x_train_bow, y_train_six_way, validation_data=(x_val_bow, y_val_six_way), batch_size=64, epochs=10)\n",
        "\n",
        "y_test = np.argmax(y_test_six_way, axis=1)\n",
        "y_pred = model.predict(x_test_bow, verbose=0)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmkqrNieuymH"
      },
      "outputs": [],
      "source": [
        "# model_bow = model.fit(x_train_bow, y_train_six_way, validation_data=(x_val_bow, y_val_six_way), batch_size=64, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeryWiHzu4lx"
      },
      "outputs": [],
      "source": [
        "# y_test = np.argmax(y_test_six_way, axis=1)\n",
        "# y_pred = model.predict(x_test_bow, verbose=0)\n",
        "# y_pred = np.argmax(y_pred, axis=1)\n",
        "# print_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0QtHU2ZO1ls"
      },
      "source": [
        "### Six way classification: **Glove**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI3sxyb7O2c6",
        "outputId": "5b9862f9-37ad-4150-cdb1-6bd2e45023a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 100)               40800     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 6)                 606       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,406\n",
            "Trainable params: 41,406\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "161/161 [==============================] - 67s 403ms/step - loss: 1.7308 - accuracy: 0.2294 - val_loss: 1.7057 - val_accuracy: 0.2812\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 53s 328ms/step - loss: 1.6842 - accuracy: 0.3010 - val_loss: 1.6655 - val_accuracy: 0.3902\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 51s 318ms/step - loss: 1.6633 - accuracy: 0.3594 - val_loss: 1.6455 - val_accuracy: 0.3785\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 51s 317ms/step - loss: 1.6420 - accuracy: 0.3697 - val_loss: 1.6241 - val_accuracy: 0.3824\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 51s 317ms/step - loss: 1.6192 - accuracy: 0.3705 - val_loss: 1.5981 - val_accuracy: 0.3871\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 51s 317ms/step - loss: 1.5932 - accuracy: 0.3978 - val_loss: 1.5732 - val_accuracy: 0.4050\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 54s 333ms/step - loss: 1.5628 - accuracy: 0.4042 - val_loss: 1.5411 - val_accuracy: 0.4089\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 51s 317ms/step - loss: 1.5241 - accuracy: 0.4107 - val_loss: 1.5098 - val_accuracy: 0.4283\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 51s 317ms/step - loss: 1.4814 - accuracy: 0.4194 - val_loss: 1.4663 - val_accuracy: 0.4291\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 51s 314ms/step - loss: 1.4382 - accuracy: 0.4234 - val_loss: 1.5412 - val_accuracy: 0.3279\n",
            "accuracy:  0.3180046765393609\n",
            "f1 score 0.3180046765393609\n",
            "Confusion Matrix: \n",
            " [[ 59   7  44  96  27  17]\n",
            " [ 23   0  29  84  69   6]\n",
            " [ 56   7  52  62  27  10]\n",
            " [ 33   1  20 141  70   2]\n",
            " [ 14   6  18  89 118   4]\n",
            " [  7   2  17   9  19  38]]\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Input((8005,1)))\n",
        "model.add(LSTM(units=100))\n",
        "model.add(Dense(units=6, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_bow = model.fit(x_train_glove, y_train_six_way, validation_data=(x_val_glove, y_val_six_way), batch_size=64, epochs=10)\n",
        "\n",
        "y_test = np.argmax(y_test_six_way, axis=1)\n",
        "y_pred = model.predict(x_test_glove, verbose=0)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aPfmQK34HyP"
      },
      "source": [
        "### Six way classification: **Bert**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xpct1gv4VN1",
        "outputId": "b1940f38-d1bf-4d28-d165-a2cbdc5ac4e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_9 (LSTM)               (None, 100)               40800     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 6)                 606       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,406\n",
            "Trainable params: 41,406\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "161/161 [==============================] - 5s 24ms/step - loss: 1.7257 - accuracy: 0.2296 - val_loss: 1.6875 - val_accuracy: 0.2757\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 5s 31ms/step - loss: 1.6159 - accuracy: 0.3234 - val_loss: 1.4983 - val_accuracy: 0.4136\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 6s 36ms/step - loss: 1.4195 - accuracy: 0.4253 - val_loss: 1.3705 - val_accuracy: 0.4393\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 6s 38ms/step - loss: 1.3315 - accuracy: 0.4481 - val_loss: 1.3313 - val_accuracy: 0.4478\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 6s 36ms/step - loss: 1.3005 - accuracy: 0.4517 - val_loss: 1.3198 - val_accuracy: 0.4408\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 6s 35ms/step - loss: 1.2846 - accuracy: 0.4517 - val_loss: 1.2838 - val_accuracy: 0.4587\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 4s 24ms/step - loss: 1.2749 - accuracy: 0.4549 - val_loss: 1.2780 - val_accuracy: 0.4556\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 1.2685 - accuracy: 0.4567 - val_loss: 1.2705 - val_accuracy: 0.4463\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 1.2664 - accuracy: 0.4558 - val_loss: 1.2727 - val_accuracy: 0.4540\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 1.2610 - accuracy: 0.4587 - val_loss: 1.2658 - val_accuracy: 0.4431\n",
            "accuracy:  0.4333593141075604\n",
            "f1 score 0.4333593141075604\n",
            "Confusion Matrix: \n",
            " [[151   2  18  10  52  17]\n",
            " [ 47  33  11  17  99   4]\n",
            " [ 55   0  61  19  66  13]\n",
            " [ 69   1  10  78 107   2]\n",
            " [ 46   0   8  14 178   3]\n",
            " [ 23   0   2   6   6  55]]\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Input((389,1)))\n",
        "model.add(LSTM(units=100))\n",
        "model.add(Dense(units=6, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_bow = model.fit(x_train_bert, y_train_six_way, validation_data=(x_val_bert, y_val_six_way), batch_size=64, epochs=10)\n",
        "\n",
        "y_test = np.argmax(y_test_six_way, axis=1)\n",
        "y_pred = model.predict(x_test_bert, verbose=0)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctoTOw2uIK1G"
      },
      "source": [
        "# Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZJUrQ1SrEBa"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA3wQH1JinNx"
      },
      "outputs": [],
      "source": [
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mk-q1zwVF5KZ"
      },
      "outputs": [],
      "source": [
        "# Function for preprocessing labels\n",
        "def dataPreprocessingBinary(data):\n",
        "    y = data[\"label\"].tolist()\n",
        "\n",
        "    # Changing the 'half-true', 'mostly-true', barely-true', 'pants-fire' labels to True/False for Binary Classification\n",
        "    for x in range(len(y)):\n",
        "        if(y[x] == 'half-true'):\n",
        "            y[x] = 'True'\n",
        "        elif(y[x] == 'mostly-true'):\n",
        "            y[x] = 'True'\n",
        "        elif(y[x] == 'barely-true'):\n",
        "            y[x] = 'False'\n",
        "        elif(y[x] == 'pants-fire'):\n",
        "            y[x] = 'False'\n",
        "\n",
        "    # Converting the lables into binary class matrix\n",
        "    labelencoder_y = LabelEncoder()\n",
        "    y = labelencoder_y.fit_transform(y)\n",
        "    y = np_utils.to_categorical(y, num_classes)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REu1ue0xbuqp"
      },
      "outputs": [],
      "source": [
        "y_train_binary = dataPreprocessingBinary(train)\n",
        "y_test_binary = dataPreprocessingBinary(test)\n",
        "y_val_binary = dataPreprocessingBinary(val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI4PIrgR01Sd"
      },
      "source": [
        "## Model\n",
        "Build a model and pass bow, glove and bert embedded inputs: x_train_bow, x_train_glove, x_train_bert(similarly validate for val and report results on test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J0inPaQb-8Y"
      },
      "outputs": [],
      "source": [
        "## write your code here\n",
        "# Initialize hyperparameters\n",
        "# Create model\n",
        "# train\n",
        "# test\n",
        "# report accuracy, f1-score and confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCkE-iBk4i_3"
      },
      "source": [
        "### Binary classification: **Bag of words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIIKJzpY4jpO",
        "outputId": "7a8ef175-6361-4526-85df-5f7933d94e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 100)               40800     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,002\n",
            "Trainable params: 41,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "161/161 [==============================] - 56s 338ms/step - loss: 0.6578 - accuracy: 0.6040 - val_loss: 0.6373 - val_accuracy: 0.6012\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 53s 331ms/step - loss: 0.6058 - accuracy: 0.6852 - val_loss: 0.5964 - val_accuracy: 0.6986\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 51s 319ms/step - loss: 0.5798 - accuracy: 0.7100 - val_loss: 0.5845 - val_accuracy: 0.6924\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 51s 319ms/step - loss: 0.5609 - accuracy: 0.7134 - val_loss: 0.5597 - val_accuracy: 0.7048\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 51s 320ms/step - loss: 0.5458 - accuracy: 0.7123 - val_loss: 0.5482 - val_accuracy: 0.6963\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 54s 333ms/step - loss: 0.5343 - accuracy: 0.7145 - val_loss: 0.5483 - val_accuracy: 0.6955\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 52s 320ms/step - loss: 0.5413 - accuracy: 0.7146 - val_loss: 0.5423 - val_accuracy: 0.6994\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 51s 320ms/step - loss: 0.5329 - accuracy: 0.7134 - val_loss: 0.5330 - val_accuracy: 0.7009\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 51s 317ms/step - loss: 0.5243 - accuracy: 0.7152 - val_loss: 0.5312 - val_accuracy: 0.6986\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 51s 317ms/step - loss: 0.5336 - accuracy: 0.7287 - val_loss: 0.5338 - val_accuracy: 0.7103\n",
            "accuracy:  0.7396726422447389\n",
            "f1 score 0.7396726422447389\n",
            "Confusion Matrix: \n",
            " [[346 210]\n",
            " [124 603]]\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Input((8005,1)))\n",
        "model.add(LSTM(units=100))\n",
        "model.add(Dense(units=2, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train_bow, y_train_binary, validation_data=(x_val_bow, y_val_binary), batch_size=64, epochs=10)\n",
        "\n",
        "y_test = np.argmax(y_test_binary, axis=1)\n",
        "y_pred = model.predict(x_test_bow, verbose=0)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6WxFUS-4keu"
      },
      "source": [
        "### Binary classification: **Glove**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zyvU-w34k3w",
        "outputId": "2181a904-32e3-433c-89a2-e7a19fb4e054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_11 (LSTM)              (None, 100)               40800     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,002\n",
            "Trainable params: 41,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "161/161 [==============================] - 53s 320ms/step - loss: 0.6536 - accuracy: 0.6153 - val_loss: 0.6252 - val_accuracy: 0.6425\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 51s 316ms/step - loss: 0.5985 - accuracy: 0.6909 - val_loss: 0.5921 - val_accuracy: 0.7056\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 51s 315ms/step - loss: 0.5747 - accuracy: 0.7126 - val_loss: 0.5701 - val_accuracy: 0.6955\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 51s 315ms/step - loss: 0.5691 - accuracy: 0.7052 - val_loss: 0.5783 - val_accuracy: 0.6916\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 50s 314ms/step - loss: 0.5588 - accuracy: 0.7102 - val_loss: 0.5671 - val_accuracy: 0.7103\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 51s 315ms/step - loss: 0.5532 - accuracy: 0.7136 - val_loss: 0.5539 - val_accuracy: 0.7033\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 51s 316ms/step - loss: 0.5409 - accuracy: 0.7125 - val_loss: 0.5405 - val_accuracy: 0.7002\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 51s 317ms/step - loss: 0.5422 - accuracy: 0.7129 - val_loss: 0.5677 - val_accuracy: 0.7025\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 51s 315ms/step - loss: 0.5440 - accuracy: 0.7252 - val_loss: 0.5356 - val_accuracy: 0.7157\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 53s 331ms/step - loss: 0.5238 - accuracy: 0.7295 - val_loss: 0.5253 - val_accuracy: 0.7087\n",
            "accuracy:  0.7357755261106781\n",
            "f1 score 0.7357755261106782\n",
            "Confusion Matrix: \n",
            " [[329 227]\n",
            " [112 615]]\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Input((8005,1)))\n",
        "model.add(LSTM(units=100))\n",
        "model.add(Dense(units=2, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train_glove, y_train_binary, validation_data=(x_val_glove, y_val_binary), batch_size=64, epochs=10)\n",
        "\n",
        "y_test = np.argmax(y_test_binary, axis=1)\n",
        "y_pred = model.predict(x_test_glove, verbose=0)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yr2ZN1R4lyk"
      },
      "source": [
        "### Binary classification: **Bert**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdbgfKt14ml5",
        "outputId": "870b4720-b1a6-4899-a02c-bbe632fa03bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_12 (LSTM)              (None, 100)               40800     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,002\n",
            "Trainable params: 41,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "161/161 [==============================] - 5s 23ms/step - loss: 0.6587 - accuracy: 0.6085 - val_loss: 0.6348 - val_accuracy: 0.6441\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.6111 - accuracy: 0.6636 - val_loss: 0.5908 - val_accuracy: 0.6760\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.5602 - accuracy: 0.7085 - val_loss: 0.5621 - val_accuracy: 0.6893\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.5410 - accuracy: 0.7150 - val_loss: 0.5392 - val_accuracy: 0.6947\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.5328 - accuracy: 0.7168 - val_loss: 0.5328 - val_accuracy: 0.7056\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.5246 - accuracy: 0.7184 - val_loss: 0.5220 - val_accuracy: 0.7111\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.5183 - accuracy: 0.7300 - val_loss: 0.5200 - val_accuracy: 0.7126\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.5150 - accuracy: 0.7298 - val_loss: 0.5212 - val_accuracy: 0.7072\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.5106 - accuracy: 0.7314 - val_loss: 0.5109 - val_accuracy: 0.7173\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 3s 20ms/step - loss: 0.5086 - accuracy: 0.7322 - val_loss: 0.5232 - val_accuracy: 0.6978\n",
            "accuracy:  0.7310989867498051\n",
            "f1 score 0.7310989867498051\n",
            "Confusion Matrix: \n",
            " [[289 267]\n",
            " [ 78 649]]\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Input((389,1)))\n",
        "model.add(LSTM(units=100))\n",
        "model.add(Dense(units=2, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train_bert, y_train_binary, validation_data=(x_val_bert, y_val_binary), batch_size=64, epochs=10)\n",
        "\n",
        "y_test = np.argmax(y_test_binary, axis=1)\n",
        "y_pred = model.predict(x_test_bert, verbose=0)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print_metrics(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "2021201060_Assignment3_Q3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}